{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "# Get utils.py\n",
    "from os.path import basename, exists\n",
    "\n",
    "def download(url):\n",
    "    filename = basename(url)\n",
    "    if not exists(filename):\n",
    "        from urllib.request import urlretrieve\n",
    "        local, _ = urlretrieve(url, filename)\n",
    "        print('Downloaded ' + local)\n",
    "    \n",
    "# download('https://github.com/AllenDowney/ThinkBayes2/raw/master/soln/utils.py')\n",
    "\n",
    "from utils import set_pyplot_params\n",
    "\n",
    "set_pyplot_params()\n",
    "\n",
    "from utils import Or70, Pu50, Gr30\n",
    "\n",
    "color_list3 = [Or70, Pu50, Gr30]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "\n",
    "marker_cycle = cycler(marker=['s', 'o', '^'])\n",
    "color_cycle = cycler(color=color_list3)\n",
    "line_cycle = cycler(linestyle=['-', '--', ':'])\n",
    "\n",
    "plt.rcParams['axes.prop_cycle'] = (color_cycle + \n",
    "                                   marker_cycle + \n",
    "                                   line_cycle)\n",
    "\n",
    "# Load the data files from \n",
    "# https://github.com/allisonhorst/palmerpenguins\n",
    "# With gratitude to Allison Horst (@allison_horst)\n",
    "\n",
    "# download('https://github.com/allisonhorst/palmerpenguins/raw/main/inst/extdata/penguins_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('penguins_raw.csv').dropna(subset=['Body Mass (g)'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten(species):\n",
    "    return species.split()[0]\n",
    "\n",
    "df['Species2'] = df['Species'].apply(shorten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['studyName', 'Sample Number', 'Species', 'Region', 'Island', 'Stage',\n",
       "       'Individual ID', 'Clutch Completion', 'Date Egg', 'Culmen Length (mm)',\n",
       "       'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)', 'Sex',\n",
       "       'Delta 15 N (o/oo)', 'Delta 13 C (o/oo)', 'Comments', 'Species2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Culmen Length (mm)', 'Flipper Length (mm)']]\n",
    "y = df['Species2']\n",
    "y, species = pd.factorize(df['Species2'], sort = True)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.7</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.3</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>55.8</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>43.5</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>49.6</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>50.8</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>50.2</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Culmen Length (mm)  Flipper Length (mm)\n",
       "0                  39.1                181.0\n",
       "1                  39.5                186.0\n",
       "2                  40.3                195.0\n",
       "4                  36.7                193.0\n",
       "5                  39.3                190.0\n",
       "..                  ...                  ...\n",
       "339                55.8                207.0\n",
       "340                43.5                202.0\n",
       "341                49.6                193.0\n",
       "342                50.8                210.0\n",
       "343                50.2                198.0\n",
       "\n",
       "[342 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [p, mus, sigmas]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9951df15994343149864280ec854bec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 500 draw iterations (4_000 + 2_000 draws total) took 4 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    # 데이터 컨테이너 설정\n",
    "    X_data = pm.Data('X_data', X)\n",
    "    # Y의 사전확률을 베타분포로 설정\n",
    "    alpha = np.ones(3)\n",
    "    p = pm.Dirichlet('p', alpha, shape=3)\n",
    "    # Y의 베르누이 분포\n",
    "    y = pm.Categorical('y', p, observed=y)\n",
    "    # 각 클래스 및 특징(평균, 표준편차)에 대한 조건부 분포 설정\n",
    "    mus = pm.Normal('mus', mu=0, sigma=10, shape=(3, 2))  \n",
    "    sigmas = pm.HalfNormal('sigmas', sigma=1, shape=(3, 2))\n",
    "    # 특징 데이터의 조건부 분포: Y에 따라 평균과 표준편차 선택\n",
    "    X_obs = pm.Normal('X_obs'\n",
    "                        , mu=mus[y]\n",
    "                        , sigma=sigmas[y]\n",
    "                        , observed=X_data)\n",
    "    trace = pm.sample(500, return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Culmen Length (mm)', 'Flipper Length (mm)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Culmen Length (mm)</th>\n",
       "      <th>Flipper Length (mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>193</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Culmen Length (mm)  Flipper Length (mm)\n",
       "0                 193                   48"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [X_obs, y]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f952a5ce7c444bb3732ec12560fed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Output size (1, 2) is not compatible with broadcast dimensions of inputs (342, 2).\nApply node that caused the error: normal_rv{0, (0, 0), floatX, True}(RandomGeneratorSharedVariable(<Generator(PCG64) at 0x17CF8B760>), MakeVector{dtype='int64'}.0, 11, AdvancedSubtensor1.0, AdvancedSubtensor1.0)\nToposort index: 6\nInputs types: [RandomGeneratorType, TensorType(int64, shape=(2,)), TensorType(int64, shape=()), TensorType(float64, shape=(None, None)), TensorType(float64, shape=(None, None))]\nInputs shapes: ['No shapes', (2,), (), (342, 2), (342, 2)]\nInputs strides: ['No strides', (8,), (), (16, 8), (16, 8)]\nInputs values: [Generator(PCG64) at 0x17CF8B760, array([1, 2]), array(11), 'not shown', 'not shown']\nOutputs clients: [['output'], ['output']]\n\nHINT: Re-running with most PyTensor optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the PyTensor flag 'optimizer=fast_compile'. If that does not work, PyTensor optimizations can be disabled with 'optimizer=None'.\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/compile/function/types.py:970\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 970\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_subset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm(output_subset\u001b[38;5;241m=\u001b[39moutput_subset)\n\u001b[1;32m    973\u001b[0m     )\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/graph/op.py:515\u001b[0m, in \u001b[0;36mOp.make_py_thunk.<locals>.rval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;129m@is_thunk_type\u001b[39m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrval\u001b[39m(p\u001b[38;5;241m=\u001b[39mp, i\u001b[38;5;241m=\u001b[39mnode_input_storage, o\u001b[38;5;241m=\u001b[39mnode_output_storage, n\u001b[38;5;241m=\u001b[39mnode):\n\u001b[0;32m--> 515\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39moutputs:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/tensor/random/op.py:330\u001b[0m, in \u001b[0;36mRandomVariable.perform\u001b[0;34m(self, node, inputs, outputs)\u001b[0m\n\u001b[1;32m    328\u001b[0m rng_var_out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m rng\n\u001b[0;32m--> 330\u001b[0m smpl_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(smpl_val, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(smpl_val\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m!=\u001b[39m out_var\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    335\u001b[0m ):\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/tensor/random/op.py:127\u001b[0m, in \u001b[0;36mRandomVariable.rng_fn\u001b[0;34m(self, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sample a numeric random variate.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mnumpy/random/_generator.pyx:1220\u001b[0m, in \u001b[0;36mnumpy.random._generator.Generator.normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:600\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:518\u001b[0m, in \u001b[0;36mnumpy.random._common.cont_broadcast_2\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:245\u001b[0m, in \u001b[0;36mnumpy.random._common.validate_output_shape\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Output size (1, 2) is not compatible with broadcast dimensions of inputs (342, 2).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     pm\u001b[38;5;241m.\u001b[39mset_data({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_data\u001b[39m\u001b[38;5;124m'\u001b[39m: new_X})\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# 사후 예측 샘플링\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     posterior_predictive \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_posterior_predictive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     y_pred_samples \u001b[38;5;241m=\u001b[39m posterior_predictive[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 예측 결과\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pymc/sampling/forward.py:849\u001b[0m, in \u001b[0;36msample_posterior_predictive\u001b[0;34m(trace, model, var_names, sample_dims, random_seed, progressbar, progressbar_theme, return_inferencedata, extend_inferencedata, predictions, idata_kwargs, compile_kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# there's only a single chain, but the index might hit it multiple times if\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;66;03m# the number of indices is greater than the length of the trace.\u001b[39;00m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    847\u001b[0m     param \u001b[38;5;241m=\u001b[39m _trace[idx \u001b[38;5;241m%\u001b[39m len_trace]\n\u001b[0;32m--> 849\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43msampler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(vars_, values):\n\u001b[1;32m    852\u001b[0m     ppc_trace_t\u001b[38;5;241m.\u001b[39minsert(k\u001b[38;5;241m.\u001b[39mname, v, idx)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pymc/util.py:394\u001b[0m, in \u001b[0;36mpoint_wrapper.<locals>.wrapped\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    393\u001b[0m     input_point \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m ins}\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/compile/function/types.py:983\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthunks\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m         thunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm\u001b[38;5;241m.\u001b[39mthunks[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm\u001b[38;5;241m.\u001b[39mposition_of_error]\n\u001b[0;32m--> 983\u001b[0m     \u001b[43mraise_with_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_of_error\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;66;03m# old-style linkers raise their own exceptions\u001b[39;00m\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/link/utils.py:523\u001b[0m, in \u001b[0;36mraise_with_op\u001b[0;34m(fgraph, node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    518\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m error does not allow us to add an extra error message\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;66;03m# Some exception need extra parameter in inputs. So forget the\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m# extra long error message in that case.\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_trace)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/compile/function/types.py:970\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m t0_fn \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    969\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 970\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_subset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvm(output_subset\u001b[38;5;241m=\u001b[39moutput_subset)\n\u001b[1;32m    973\u001b[0m     )\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     restore_defaults()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/graph/op.py:515\u001b[0m, in \u001b[0;36mOp.make_py_thunk.<locals>.rval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;129m@is_thunk_type\u001b[39m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrval\u001b[39m(p\u001b[38;5;241m=\u001b[39mp, i\u001b[38;5;241m=\u001b[39mnode_input_storage, o\u001b[38;5;241m=\u001b[39mnode_output_storage, n\u001b[38;5;241m=\u001b[39mnode):\n\u001b[0;32m--> 515\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39moutputs:\n\u001b[1;32m    517\u001b[0m         compute_map[o][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/tensor/random/op.py:330\u001b[0m, in \u001b[0;36mRandomVariable.perform\u001b[0;34m(self, node, inputs, outputs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     rng \u001b[38;5;241m=\u001b[39m copy(rng)\n\u001b[1;32m    328\u001b[0m rng_var_out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m rng\n\u001b[0;32m--> 330\u001b[0m smpl_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(smpl_val, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(smpl_val\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m!=\u001b[39m out_var\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    335\u001b[0m ):\n\u001b[1;32m    336\u001b[0m     smpl_val \u001b[38;5;241m=\u001b[39m _asarray(smpl_val, dtype\u001b[38;5;241m=\u001b[39mout_var\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/BayesianInference/lib/python3.10/site-packages/pytensor/tensor/random/op.py:127\u001b[0m, in \u001b[0;36mRandomVariable.rng_fn\u001b[0;34m(self, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrng_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, rng, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sample a numeric random variate.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mnumpy/random/_generator.pyx:1220\u001b[0m, in \u001b[0;36mnumpy.random._generator.Generator.normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:600\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:518\u001b[0m, in \u001b[0;36mnumpy.random._common.cont_broadcast_2\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:245\u001b[0m, in \u001b[0;36mnumpy.random._common.validate_output_shape\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Output size (1, 2) is not compatible with broadcast dimensions of inputs (342, 2).\nApply node that caused the error: normal_rv{0, (0, 0), floatX, True}(RandomGeneratorSharedVariable(<Generator(PCG64) at 0x17CF8B760>), MakeVector{dtype='int64'}.0, 11, AdvancedSubtensor1.0, AdvancedSubtensor1.0)\nToposort index: 6\nInputs types: [RandomGeneratorType, TensorType(int64, shape=(2,)), TensorType(int64, shape=()), TensorType(float64, shape=(None, None)), TensorType(float64, shape=(None, None))]\nInputs shapes: ['No shapes', (2,), (), (342, 2), (342, 2)]\nInputs strides: ['No strides', (8,), (), (16, 8), (16, 8)]\nInputs values: [Generator(PCG64) at 0x17CF8B760, array([1, 2]), array(11), 'not shown', 'not shown']\nOutputs clients: [['output'], ['output']]\n\nHINT: Re-running with most PyTensor optimizations disabled could provide a back-trace showing when this node was created. This can be done by setting the PyTensor flag 'optimizer=fast_compile'. If that does not work, PyTensor optimizations can be disabled with 'optimizer=None'.\nHINT: Use the PyTensor flag `exception_verbosity=high` for a debug print-out and storage map footprint of this Apply node."
     ]
    }
   ],
   "source": [
    "# 새로운 데이터\n",
    "new_X = pd.DataFrame([[193, 48]],columns = X.columns)\n",
    "with model:\n",
    "    # 데이터 업데이트\n",
    "    pm.set_data({'X_data': new_X})\n",
    "    # 사후 예측 샘플링\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace)\n",
    "    y_pred_samples = posterior_predictive['y']\n",
    "# 예측 결과\n",
    "from scipy.stats import mode\n",
    "y_pred = mode(y_pred_samples, axis=0).mode[0]\n",
    "print(f\"Predicted label for new X = [3, 5.2, 9] is {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"390pt\" height=\"405pt\"\n",
       " viewBox=\"0.00 0.00 390.00 405.45\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 401.45)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-401.45 386,-401.45 386,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M30,-267.63C30,-267.63 112,-267.63 112,-267.63 118,-267.63 124,-273.63 124,-279.63 124,-279.63 124,-377.45 124,-377.45 124,-383.45 118,-389.45 112,-389.45 112,-389.45 30,-389.45 30,-389.45 24,-389.45 18,-383.45 18,-377.45 18,-377.45 18,-279.63 18,-279.63 18,-273.63 24,-267.63 30,-267.63\"/>\n",
       "<text text-anchor=\"middle\" x=\"112.62\" y=\"-274.83\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster1 x 4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154,-137.82C154,-137.82 362,-137.82 362,-137.82 368,-137.82 374,-143.82 374,-149.82 374,-149.82 374,-247.63 374,-247.63 374,-253.63 368,-259.63 362,-259.63 362,-259.63 154,-259.63 154,-259.63 148,-259.63 142,-253.63 142,-247.63 142,-247.63 142,-149.82 142,-149.82 142,-143.82 148,-137.82 154,-137.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"352.12\" y=\"-145.02\" font-family=\"Times,serif\" font-size=\"14.00\">1 x 4</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster10000</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-137.82C20,-137.82 122,-137.82 122,-137.82 128,-137.82 134,-143.82 134,-149.82 134,-149.82 134,-247.63 134,-247.63 134,-253.63 128,-259.63 122,-259.63 122,-259.63 20,-259.63 20,-259.63 14,-259.63 8,-253.63 8,-247.63 8,-247.63 8,-149.82 8,-149.82 8,-143.82 14,-137.82 20,-137.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"109.12\" y=\"-145.02\" font-family=\"Times,serif\" font-size=\"14.00\">10000</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster150 x 4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171,-8C171,-8 245,-8 245,-8 251,-8 257,-14 257,-20 257,-20 257,-117.82 257,-117.82 257,-123.82 251,-129.82 245,-129.82 245,-129.82 171,-129.82 171,-129.82 165,-129.82 159,-123.82 159,-117.82 159,-117.82 159,-20 159,-20 159,-14 165,-8 171,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"228.38\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"14.00\">150 x 4</text>\n",
       "</g>\n",
       "<!-- pi -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>pi</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"71\" cy=\"-340.79\" rx=\"45.25\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-352.24\" font-family=\"Times,serif\" font-size=\"14.00\">pi</text>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-335.74\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-319.24\" font-family=\"Times,serif\" font-size=\"14.00\">Dirichlet</text>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"71\" cy=\"-210.98\" rx=\"55.33\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-222.43\" font-family=\"Times,serif\" font-size=\"14.00\">z</text>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-205.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"71\" y=\"-189.43\" font-family=\"Times,serif\" font-size=\"14.00\">Categorical</text>\n",
       "</g>\n",
       "<!-- pi&#45;&gt;z -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>pi&#45;&gt;z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M71,-299.7C71,-288.16 71,-275.41 71,-263.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"74.5,-263.44 71,-253.44 67.5,-263.44 74.5,-263.44\"/>\n",
       "</g>\n",
       "<!-- mu -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>mu</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"325\" cy=\"-210.98\" rx=\"41.01\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"325\" y=\"-222.43\" font-family=\"Times,serif\" font-size=\"14.00\">mu</text>\n",
       "<text text-anchor=\"middle\" x=\"325\" y=\"-205.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"325\" y=\"-189.43\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- xi -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>xi</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"208\" cy=\"-81.16\" rx=\"41.01\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-92.61\" font-family=\"Times,serif\" font-size=\"14.00\">xi</text>\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-76.11\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-59.61\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- mu&#45;&gt;xi -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>mu&#45;&gt;xi</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M304.13,-175.86C295.77,-163.33 285.61,-149.39 275,-137.82 267.26,-129.37 258.24,-121.05 249.36,-113.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"251.7,-110.91 241.76,-107.24 247.24,-116.31 251.7,-110.91\"/>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"208\" cy=\"-210.98\" rx=\"57.98\" ry=\"40.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-222.43\" font-family=\"Times,serif\" font-size=\"14.00\">sigma</text>\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-205.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text text-anchor=\"middle\" x=\"208\" y=\"-189.43\" font-family=\"Times,serif\" font-size=\"14.00\">HalfNormal</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;xi -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;xi</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208,-169.88C208,-158.34 208,-145.6 208,-133.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.5,-133.62 208,-123.62 204.5,-133.62 211.5,-133.62\"/>\n",
       "</g>\n",
       "<!-- z&#45;&gt;xi -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>z&#45;&gt;xi</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M100.35,-176.28C111.71,-163.8 125.08,-149.78 138,-137.82 146.89,-129.58 156.87,-121.19 166.44,-113.51\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"168.59,-116.28 174.26,-107.33 164.25,-110.79 168.59,-116.28\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x17c3025c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    alpha = np.ones(1)\n",
    "    pi = pm.Dirichlet('pi', alpha, shape=1)\n",
    "    mu = pm.Normal('mu', mu=0, sigma=100, shape=(1, # num_cats\n",
    "                                                4)) # num_preds\n",
    "    sigma = pm.HalfNormal('sigma', 100, shape=(1,\n",
    "                                                4))\n",
    "    # Assign classes to data points\n",
    "    z = pm.Categorical('z', pi, shape=10000,\n",
    "                        observed=y)\n",
    "\n",
    "    # The components are independent and normally distributed\n",
    "    xi = pm.Normal('xi', mu=mu[z], sigma=sigma[z], observed=X)\n",
    "\n",
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesianInference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
